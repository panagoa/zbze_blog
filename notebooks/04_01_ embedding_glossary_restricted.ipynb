{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "vector_size = 100\n",
    "\n",
    "kbd_model = fasttext.load_model(f'../data/processed/embeddings/fasttext_skipgram_kbd_{vector_size}.bin')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:47:35.484557Z",
     "start_time": "2024-02-10T20:47:35.481696Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kbd_rus_glossary_df = pd.read_csv('../data/processed/glossary/html_cleaned/Ady-Ady_AP.csv')\n",
    "\n",
    "kbd_rus_glossary_df = kbd_rus_glossary_df.rename(\n",
    "    columns={\n",
    "        '#name': 'word',\n",
    "        'Адыгэбзэ псалъалъэ (Ady) (eastern)': 'description'}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:47:36.113684Z",
     "start_time": "2024-02-10T20:47:35.975872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "glossary_kbd_words = set(kbd_rus_glossary_df['word'].values)\n",
    "glossary_kbd_words = {word.lower().replace('i', 'I') for word in glossary_kbd_words}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:47:36.620998Z",
     "start_time": "2024-02-10T20:47:36.610679Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27268/27268 [00:00<00:00, 67335.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Сохраним вектора только для слов из словаря. (так мы получим похожие слова в словарной форме)\n",
    "kbd_restricted_glossary_kv = KeyedVectors(vector_size=vector_size, count=len(glossary_kbd_words))\n",
    "for word in tqdm(glossary_kbd_words):\n",
    "    kbd_restricted_glossary_kv.add_vector(word, kbd_model.get_word_vector(word))\n",
    "\n",
    "kbd_restricted_glossary_kv.save(f'../data/processed/embeddings/fasttext_skipgram_kbd_{vector_size}_restricted_glossary.kv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:47:37.524986Z",
     "start_time": "2024-02-10T20:47:37.074354Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27268 [00:00<?, ?it/s]/Users/panagoa/PycharmProjects/zbze_blog/venv/lib/python3.11/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      " 19%|█▊        | 5064/27268 [00:05<00:18, 1196.56it/s]/Users/panagoa/PycharmProjects/zbze_blog/venv/lib/python3.11/site-packages/gensim/models/keyedvectors.py:449: RuntimeWarning: invalid value encountered in divide\n",
      "  result = self.vectors[index] / self.norms[index]\n",
      "100%|██████████| 27268/27268 [00:26<00:00, 1038.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Сгруппируем похожие слова для каждого слова из словаря.\n",
    "glossary_word_groups_by_glossary_words = {}\n",
    "\n",
    "for word in tqdm(glossary_kbd_words):\n",
    "    similar_glossary_words = [w for w, _ in kbd_restricted_glossary_kv.most_similar(word, topn=10)]\n",
    "    glossary_word_groups_by_glossary_words[word] = similar_glossary_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:48:04.558395Z",
     "start_time": "2024-02-10T20:47:38.276966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# \"теплъафIэ\": [\n",
    "#     \"теплъэншэ\",\n",
    "#     \"теплъэ\",\n",
    "#     \"теплъаджэ\",\n",
    "#     \"фэтеплъэ\",\n",
    "#     \"теплъэн\",\n",
    "#     \"теплъызэн\",\n",
    "#     \"фафIэ\",\n",
    "#     \"лыфIэ\",\n",
    "#     \"фIэрафIэ\",\n",
    "#     \"теплъэгъуей\"\n",
    "# ],\n",
    "with open('../data/processed/word_groups/glossary_word_groups_by_glossary_words.json', 'w') as f:\n",
    "    json.dump(glossary_word_groups_by_glossary_words, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:48:05.416715Z",
     "start_time": "2024-02-10T20:48:05.293714Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179574/179574 [00:01<00:00, 138182.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# соберем слова и векторы из текста отфильтровав слова\n",
    "\n",
    "file_name = 'freq_1000000_oshhamaho.csv'\n",
    "\n",
    "df = pd.read_csv(f'../data/processed/word_freqs/{file_name}', sep=',')\n",
    "words = df[df['freq'] > 1]['word'].values.tolist()\n",
    "\n",
    "kbd_restricted_kv = KeyedVectors(vector_size=100, count=len(words))\n",
    "for word in tqdm(words):\n",
    "    kbd_restricted_kv.add_vector(word, kbd_model.get_word_vector(word))\n",
    "\n",
    "kbd_restricted_kv.save(f'../data/processed/embeddings/fasttext_skipgram_kbd_{vector_size}_restricted_{file_name}.kv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:48:08.036579Z",
     "start_time": "2024-02-10T20:48:06.320363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27268 [00:00<?, ?it/s]/Users/panagoa/PycharmProjects/zbze_blog/venv/lib/python3.11/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "100%|██████████| 27268/27268 [02:07<00:00, 214.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# cгруппируем похожие слова для каждого слова из текста \n",
    "# (так мы получим похожие слова и различные формы слов)\n",
    "\n",
    "word_groups_by_glossary_words = {}\n",
    "\n",
    "for word in tqdm(glossary_kbd_words):\n",
    "    word_vector = kbd_model.get_word_vector(word)\n",
    "    similar_words = [w for w, _ in kbd_restricted_kv.similar_by_vector(word_vector, topn=30)]\n",
    "    word_groups_by_glossary_words[word] = similar_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:50:15.334551Z",
     "start_time": "2024-02-10T20:48:08.050276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# \"теплъафIэ\": [\n",
    "#     \"теплъафIэ\",\n",
    "#     \"теплъафIэр\",\n",
    "#     \"теплъафIэт\",\n",
    "#     \"теплъафIэм\",\n",
    "#     \"теплъа\",\n",
    "#     \"теплъэф\",\n",
    "#     \"теплъи\",\n",
    "#     \"теплъаджэт\",\n",
    "#     \"теплъэ…\",\n",
    "#     \"теплъэт\"\n",
    "#     ],\n",
    "\n",
    "with open('../data/processed/word_groups/word_groups_by_glossary_words.json', 'w') as f:\n",
    "    json.dump(word_groups_by_glossary_words, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:50:15.729744Z",
     "start_time": "2024-02-10T20:50:15.337404Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Если обучить модель на тексте где слова будут заменены на словарную форму или если убрать множество суффиксов, то мы получим более точную и полезную модель.\n",
    "\n",
    "Можно попробовать смешать подходы и собрать текст с разными модификациями слов:\n",
    "\n",
    "1. Текст где слова будут без суффиксов.\n",
    "2. Текст где слова будут без префиксов.\n",
    "3. Текст где слова будут без суффиксов и префиксов.\n",
    "4. Текст где слова будут в словарной форме.\n",
    "\n",
    "То есть, из одного предложения мы можем собрать множество предложений с разными модификациями отделенных слов.\n",
    "\n",
    "Предположительно, так вес корневой морфемы будет больше и модель будет лучше.\n",
    "\n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
