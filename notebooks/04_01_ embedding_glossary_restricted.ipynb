{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "kbd_model = fasttext.load_model('../data/processed/embeddings/fasttext_skipgram_kbd_300.bin')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:48:20.897131Z",
     "start_time": "2024-01-07T20:48:15.646653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kbd_rus_glossary_df = pd.read_csv('../data/processed/glossary/html_cleaned/Ady-Ady_AP.csv')\n",
    "\n",
    "kbd_rus_glossary_df = kbd_rus_glossary_df.rename(\n",
    "    columns={\n",
    "        '#name': 'word',\n",
    "        'Адыгэбзэ псалъалъэ (Ady) (eastern)': 'description'}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T20:48:25.221071Z",
     "start_time": "2024-01-07T20:48:24.583305Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "glossary_kbd_words = set(kbd_rus_glossary_df['word'].values)\n",
    "glossary_kbd_words = {word.lower().replace('i', 'I') for word in glossary_kbd_words}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:08:40.441372Z",
     "start_time": "2024-01-07T21:08:40.435569Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27268/27268 [00:00<00:00, 89327.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Сохраним вектора только для слов из словаря. (так мы получим похожие слова в словарной форме)\n",
    "kbd_restricted_glossary_kv = KeyedVectors(vector_size=300, count=len(glossary_kbd_words))\n",
    "for word in tqdm(glossary_kbd_words):\n",
    "    kbd_restricted_glossary_kv.add_vector(word, kbd_model.get_word_vector(word))\n",
    "\n",
    "kbd_restricted_glossary_kv.save('../data/processed/embeddings/fasttext_skipgram_kbd_300_restricted_glossary.kv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:09:20.424048Z",
     "start_time": "2024-01-07T21:09:20.031175Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Сгруппируем похожие слова для каждого слова из словаря.\n",
    "glossary_word_groups_by_glossary_words = {}\n",
    "\n",
    "for word in tqdm(glossary_kbd_words):\n",
    "    similar_glossary_words = [w for w, _ in kbd_restricted_glossary_kv.most_similar(word, topn=10)]\n",
    "    glossary_word_groups_by_glossary_words[word] = similar_glossary_words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27268/27268 [00:42<00:00, 640.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# \"теплъафIэ\": [\n",
    "#     \"теплъэншэ\",\n",
    "#     \"теплъэ\",\n",
    "#     \"теплъаджэ\",\n",
    "#     \"фэтеплъэ\",\n",
    "#     \"теплъэн\",\n",
    "#     \"теплъызэн\",\n",
    "#     \"фафIэ\",\n",
    "#     \"лыфIэ\",\n",
    "#     \"фIэрафIэ\",\n",
    "#     \"теплъэгъуей\"\n",
    "# ],\n",
    "with open('../data/processed/word_groups/glossary_word_groups_by_glossary_words.json', 'w') as f:\n",
    "    json.dump(glossary_word_groups_by_glossary_words, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-07T20:59:48.380046Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179574/179574 [00:02<00:00, 71765.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# соберем слова и векторы из текста отфильтровав слова\n",
    "\n",
    "file_name = 'freq_1000000_oshhamaho.csv'\n",
    "\n",
    "df = pd.read_csv(f'../data/processed/word_freqs/{file_name}', sep=',')\n",
    "words = df[df['freq'] > 1]['word'].values.tolist()\n",
    "\n",
    "kbd_restricted_kv = KeyedVectors(vector_size=300, count=len(words))\n",
    "for word in tqdm(words):\n",
    "    kbd_restricted_kv.add_vector(word, kbd_model.get_word_vector(word))\n",
    "\n",
    "kbd_restricted_kv.save(f'../data/processed/embeddings/fasttext_skipgram_kbd_300_restricted_{file_name}.kv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-07T21:13:50.634242Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27268/27268 [05:10<00:00, 87.78it/s] \n"
     ]
    }
   ],
   "source": [
    "# cгруппируем похожие слова для каждого слова из текста \n",
    "# (так мы получим похожие слова и различные формы слов)\n",
    "\n",
    "word_groups_by_glossary_words = {}\n",
    "\n",
    "for word in tqdm(glossary_kbd_words):\n",
    "    word_vector = kbd_model.get_word_vector(word)\n",
    "    similar_words = [w for w, _ in kbd_restricted_kv.similar_by_vector(word_vector, topn=10)]\n",
    "    word_groups_by_glossary_words[word] = similar_words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:25:22.513264Z",
     "start_time": "2024-01-07T21:20:11.849923Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# \"теплъафIэ\": [\n",
    "#     \"теплъафIэ\",\n",
    "#     \"теплъафIэр\",\n",
    "#     \"теплъафIэт\",\n",
    "#     \"теплъафIэм\",\n",
    "#     \"теплъа\",\n",
    "#     \"теплъэф\",\n",
    "#     \"теплъи\",\n",
    "#     \"теплъаджэт\",\n",
    "#     \"теплъэ…\",\n",
    "#     \"теплъэт\"\n",
    "#     ],\n",
    "\n",
    "with open('../data/processed/word_groups/word_groups_by_glossary_words.json', 'w') as f:\n",
    "    json.dump(word_groups_by_glossary_words, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T21:27:45.037162Z",
     "start_time": "2024-01-07T21:27:44.921244Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Если обучить модель на тексте где слова будут заменены на словарную форму или если убрать множество суффиксов, то мы получим более точную и полезную модель.\n",
    "\n",
    "Можно попробовать смешать подходы и собрать текст с разными модификациями слов:\n",
    "\n",
    "1. Текст где слова будут без суффиксов.\n",
    "2. Текст где слова будут без префиксов.\n",
    "3. Текст где слова будут без суффиксов и префиксов.\n",
    "4. Текст где слова будут в словарной форме.\n",
    "\n",
    "То есть, из одного предложения мы можем собрать множество предложений с разными модификациями отделенных слов.\n",
    "\n",
    "Предположительно, так вес корневой морфемы будет больше и модель будет лучше.\n",
    "\n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
