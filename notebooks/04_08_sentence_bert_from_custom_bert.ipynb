{
 "cells": [
  {
   "cell_type": "code",
   "id": "dd741d41225be5fd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T10:17:41.752297Z",
     "start_time": "2024-08-14T10:17:38.669943Z"
    }
   },
   "source": [
    "from sentence_transformers import SentencesDataset, InputExample, losses, util\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "bert_model = AutoModel.from_pretrained('./mlm_bert')\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('./mlm_bert')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T10:17:49.464158Z",
     "start_time": "2024-08-14T10:17:49.195282Z"
    }
   },
   "id": "6f200d3a63f143b0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ./mlm_bert and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "3645987ea192531c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T10:17:54.879205Z",
     "start_time": "2024-08-14T10:17:51.514234Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "example_hash = set()\n",
    "train_examples = []\n",
    "\n",
    "sent_pairs_df = pd.read_csv('../data/processed/sent_pairs.csv')\n",
    "\n",
    "for sent_1, sent_2, final_score in sent_pairs_df[['sent1', 'sent2', 'final_score']].values:\n",
    "    train_examples.append(\n",
    "    InputExample(texts=[sent_1, sent_2], label=round(float(final_score), 2))\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "d34141169f078685",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T10:17:56.302168Z",
     "start_time": "2024-08-14T10:17:55.890777Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "# Обертка вашей модели BERT в модуль для SBERT\n",
    "word_embedding_model = models.Transformer(\n",
    "    './mlm_bert',\n",
    "    max_seq_length=256,\n",
    "    do_lower_case=False,\n",
    ")\n",
    "\n",
    "# Создание модели пулинга (pooling). Это сокращает все токенные векторы до одного вектора предложения\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "# Создание объекта SentenceTransformer с использованием модели BERT и модели пулинга\n",
    "sbert_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ./mlm_bert and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Создание и загрузка датасета\n",
    "train_dataset = SentencesDataset(examples=train_examples, model=sbert_model)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Настройка процесса обучения\n",
    "train_loss = losses.CosineSimilarityLoss(model=sbert_model)\n",
    "\n",
    "# Обучение модели\n",
    "# sbert_model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1)"
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-08-14T10:17:57.130334Z",
     "start_time": "2024-08-14T10:17:57.120720Z"
    }
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "sbert_model.save('./sbert_from_mlm_bert')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T10:17:58.813623Z",
     "start_time": "2024-08-14T10:17:58.500266Z"
    }
   },
   "id": "9a43670d8565d894",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "sentences1 = [\n",
    "    '1567 гъэм и бжьыхьэм кърым пащтыхьищ, дзэшхуэхэр я гъусэу, адыгэхэм я щIыр къазэуну игъэкIуащ.',\n",
    "    'КIуащ БетIал 1920 гъэм ноябрым и 22-м Дохъушыкъуей (Старэ Шэрэдж) къуажэм къыщалъхуащ.',\n",
    "    'Хэку зауэшхуэр къызэрыхъейуэ, 1941 гъэм июным и 24-м Мухьэдин зауэм кIуащ.',\n",
    "    'Уэ езым болъагъу абы и Iуэху зыIутыр.',\n",
    "    'хэт уэ уи цIэр?',\n",
    "]\n",
    "\n",
    "sentences2 = [\n",
    "    'бжьыхьэм, 1567 гъэм, кърым пащтыхьищ, дзэшхуэхэр я гъусэу, адыгэхэм я щIыр къазэуну игъэкIуащ.',\n",
    "    '1920 гъэм етIанэу гвардие хужьыр зэтрикъутащ – генералу 4-рэ офицеру 60-рэ гъэру иубыдащ.',\n",
    "    '1941 гъэм и октябрым ЩоджэнцIыкIум зауэм дэкIыну зэрыхуеймкIэ лъэIу тхылъ етх.',\n",
    "    '– къищIащ абы щIалэхэм я Iуэху зыIутыр.',\n",
    "    'cэ си цIэр Iэдэм',\n",
    "]\n",
    "\n",
    "# Compute embedding for both lists\n",
    "embeddings1 = sbert_model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = sbert_model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "# Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "        sentences1[i], sentences2[i], cosine_scores[i][i]\n",
    "    ), end='\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T10:18:19.883836Z",
     "start_time": "2024-08-14T10:18:19.512869Z"
    }
   },
   "id": "5d969ed52978ced1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567 гъэм и бжьыхьэм кърым пащтыхьищ, дзэшхуэхэр я гъусэу, адыгэхэм я щIыр къазэуну игъэкIуащ. \t\t бжьыхьэм, 1567 гъэм, кърым пащтыхьищ, дзэшхуэхэр я гъусэу, адыгэхэм я щIыр къазэуну игъэкIуащ. \t\t Score: 0.9358\n",
      "\n",
      "КIуащ БетIал 1920 гъэм ноябрым и 22-м Дохъушыкъуей (Старэ Шэрэдж) къуажэм къыщалъхуащ. \t\t 1920 гъэм етIанэу гвардие хужьыр зэтрикъутащ – генералу 4-рэ офицеру 60-рэ гъэру иубыдащ. \t\t Score: 0.7052\n",
      "\n",
      "Хэку зауэшхуэр къызэрыхъейуэ, 1941 гъэм июным и 24-м Мухьэдин зауэм кIуащ. \t\t 1941 гъэм и октябрым ЩоджэнцIыкIум зауэм дэкIыну зэрыхуеймкIэ лъэIу тхылъ етх. \t\t Score: 0.6028\n",
      "\n",
      "Уэ езым болъагъу абы и Iуэху зыIутыр. \t\t – къищIащ абы щIалэхэм я Iуэху зыIутыр. \t\t Score: 0.8375\n",
      "\n",
      "хэт уэ уи цIэр? \t\t cэ си цIэр Iэдэм \t\t Score: 0.5879\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a3733e0559aeb6e2",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
