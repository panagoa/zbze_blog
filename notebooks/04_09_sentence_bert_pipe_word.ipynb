{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd741d41225be5fd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:52:26.938205Z",
     "start_time": "2024-03-24T23:52:26.924413Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentencesDataset, InputExample, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3645987ea192531c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:52:27.870018Z",
     "start_time": "2024-03-24T23:52:27.860741Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def prepare_data_for_training(sent_pairs_df: pd.DataFrame = None):\n",
    "    train_examples = []\n",
    "\n",
    "    for sent_1, sent_2, final_score in sent_pairs_df[['sent1', 'sent2', 'final_score']].values:\n",
    "        train_examples.append(\n",
    "            InputExample(texts=[sent_1, sent_2], label=round(float(final_score), 2))\n",
    "        )\n",
    "    return train_examples"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_training(from_model_path: str, to_model_path: str, train_examples):\n",
    "    model = SentenceTransformer(from_model_path)\n",
    "\n",
    "    # Создание и загрузка датасета\n",
    "    train_dataset = SentencesDataset(examples=train_examples, model=model)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "    # Настройка процесса обучения\n",
    "    train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "    # Обучение модели\n",
    "    model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1)\n",
    "    model.save(to_model_path)\n",
    "\n",
    "    return to_model_path"
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-03-24T23:52:28.586966Z",
     "start_time": "2024-03-24T23:52:28.571873Z"
    }
   },
   "id": "initial_id",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:52:29.299060Z",
     "start_time": "2024-03-24T23:52:29.291047Z"
    }
   },
   "id": "f421aed747181a44",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "kbd_model = fasttext.load_model('../data/processed/embeddings/fasttext_skipgram_kbd_100.bin')\n",
    "\n",
    "\n",
    "words_df = pd.read_csv('../data/processed/word_freqs/freq_1000000_oshhamaho.csv')\n",
    "words_df = words_df[words_df['freq'] > 1]\n",
    "all_words = set(words_df['word'].tolist())\n",
    "\n",
    "def select_word_pairs(iteration, samples=1000):\n",
    "    words = words_df.sample(samples)['word'].tolist()\n",
    "    words_pair = [\n",
    "        (word, word_p, round(score, 3))\n",
    "        for word in tqdm(words)\n",
    "        for score, word_p, in kbd_model.get_nearest_neighbors(word, 20)\n",
    "        if word_p in all_words\n",
    "    ]\n",
    "    words_pair_df = pd.DataFrame(words_pair, columns=['sent1', 'sent2', 'final_score'])\n",
    "    words_pair_df.to_csv(f'../data/processed/word_pairs_{iteration}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:52:35.334635Z",
     "start_time": "2024-03-24T23:52:35.007033Z"
    }
   },
   "id": "2409854bccb9d541",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [05:41<00:00, 29.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdec2657c9404be5870278178b0056ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Iteration:   0%|          | 0/10314 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7154462d1fe40e5a7f5764122efbabe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [05:56<00:00, 28.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe2ecc326b0c40e990377bba3213fc64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Iteration:   0%|          | 0/10421 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da4dc2edb688410596fa3325565924f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 260/10000 [00:08<05:30, 29.50it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m to_model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./sbert_from_mlm_bert_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00miteration\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      5\u001B[0m model_from \u001B[38;5;241m=\u001B[39m SentenceTransformer(from_model_path)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mselect_word_pairs\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m sent_pairs_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/processed/word_pairs_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00miteration\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      9\u001B[0m train_examples \u001B[38;5;241m=\u001B[39m prepare_data_for_training(sent_pairs_df)\n",
      "Cell \u001B[0;32mIn[51], line 12\u001B[0m, in \u001B[0;36mselect_word_pairs\u001B[0;34m(iteration, samples)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect_word_pairs\u001B[39m(iteration, samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m):\n\u001B[1;32m     11\u001B[0m     words \u001B[38;5;241m=\u001B[39m words_df\u001B[38;5;241m.\u001B[39msample(samples)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mword\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m---> 12\u001B[0m     words_pair \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword_p\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mround\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mscore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mword\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwords\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mscore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword_p\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkbd_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_nearest_neighbors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mword_p\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mall_words\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     18\u001B[0m     words_pair_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(words_pair, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msent1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msent2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfinal_score\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     19\u001B[0m     words_pair_df\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/processed/word_pairs_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00miteration\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[51], line 15\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect_word_pairs\u001B[39m(iteration, samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m):\n\u001B[1;32m     11\u001B[0m     words \u001B[38;5;241m=\u001B[39m words_df\u001B[38;5;241m.\u001B[39msample(samples)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mword\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m     12\u001B[0m     words_pair \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     13\u001B[0m         (word, word_p, \u001B[38;5;28mround\u001B[39m(score, \u001B[38;5;241m3\u001B[39m))\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m tqdm(words)\n\u001B[0;32m---> 15\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m score, word_p, \u001B[38;5;129;01min\u001B[39;00m \u001B[43mkbd_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_nearest_neighbors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m word_p \u001B[38;5;129;01min\u001B[39;00m all_words\n\u001B[1;32m     17\u001B[0m     ]\n\u001B[1;32m     18\u001B[0m     words_pair_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(words_pair, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msent1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msent2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfinal_score\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     19\u001B[0m     words_pair_df\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/processed/word_pairs_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00miteration\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/zbze_blog/venv/lib/python3.11/site-packages/fasttext/FastText.py:145\u001B[0m, in \u001B[0;36m_FastText.get_nearest_neighbors\u001B[0;34m(self, word, k, on_unicode_error)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_nearest_neighbors\u001B[39m(\u001B[38;5;28mself\u001B[39m, word, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, on_unicode_error\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetNN\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon_unicode_error\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(75, 80):\n",
    "    from_model_path = f'./sbert_from_mlm_bert_{iteration}'\n",
    "    to_model_path = f'./sbert_from_mlm_bert_{iteration + 1}'\n",
    "\n",
    "    model_from = SentenceTransformer(from_model_path)\n",
    "    select_word_pairs(iteration, samples=10000)\n",
    "    \n",
    "    sent_pairs_df = pd.read_csv(f'../data/processed/word_pairs_{iteration}.csv')\n",
    "    train_examples = prepare_data_for_training(sent_pairs_df)\n",
    "    run_training(from_model_path, to_model_path, train_examples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T00:32:48.911627Z",
     "start_time": "2024-03-24T23:52:37.095605Z"
    }
   },
   "id": "9c46d67a5ea61d16",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e2efc98bca4d66ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
